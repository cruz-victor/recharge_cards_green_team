{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <h3 style=\"font-weight: bold; color: white; font-size: 30px\">PROCESO PARA LA DETECCION DE TARJETAS DE RECARGA DE CREDITO (ENTEL, TIGO, VIVA)</h3>\n",
    "    Integrantes del equipo:<br>\n",
    "    Victor Cruz Gomez<br>\n",
    "    Eugenio Condori\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=\"orange\">1. Activar la camara del telefono movil.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Iniciar la captura de video desde la webcam (generalmente es el dispositivo 0)\n",
    "video_path= r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\data\\test_video\\videoTarjetas.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Obtener la tasa de fotogramas del video\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "wait_time=int(1000/fps)\n",
    "print(wait_time)\n",
    "\n",
    "while True:\n",
    "    # Leer un cuadro (frame) de la webcam\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Fin del video\")\n",
    "        break\n",
    "    \n",
    "    # Mostrar el cuadro en una ventana\n",
    "    # frameRotate = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    # cv2.imshow('Webcam', frameRotate)\n",
    "    \n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # Romper el bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=\"orange\">2. Dibujar un recuadro semitransparente en el video de la camara celular.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Iniciar la captura de video desde la webcam (generalmente es el dispositivo 0)\n",
    "video_path= r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\data\\test_video\\videoTarjetas.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Obtener la tasa de fotogramas del video\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "wait_time=int(1000/fps)\n",
    "print(wait_time)\n",
    "\n",
    "while True:\n",
    "    # Leer un cuadro (frame) de la webcam\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"No se pudo obtener el cuadro de video\")\n",
    "        break\n",
    "    \n",
    "    # Obtener el alto y ancho del cuadro\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    # Calcular el tamaño del rectángulo para que ocupe el 80% del cuadro\n",
    "    rect_width = int(width * 0.95)\n",
    "    rect_height = int(height * 0.55)\n",
    "    \n",
    "    # Calcular el punto de inicio (superior izquierda) y final (inferior derecha) del rectángulo\n",
    "    start_point = (int((width - rect_width) / 2), int((height - rect_height) / 2))\n",
    "    end_point = (int((width + rect_width) / 2), int((height + rect_height) / 2))\n",
    "    \n",
    "    # Configurar el color y grosor del rectángulo\n",
    "    color = (0, 255, 0)  # Verde\n",
    "    thickness = 2        # Grosor de la línea\n",
    "    \n",
    "    # Dibujar el rectángulo en el cuadro\n",
    "    cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "    \n",
    "    # Mostrar el cuadro en una ventana\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # Romper el bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">**3. Capturar foto de la tarjeta de recarga la operadora de telefonos.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iniciar la captura de video desde la webcam (generalmente es el dispositivo 0)\n",
    "video_path= r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\data\\test_video\\videoTarjetas.mp4'\n",
    "photo_video_path= r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\data\\test_photos_video'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Obtener la tasa de fotogramas del video\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "wait_time=int(1000/fps)\n",
    "print(wait_time)\n",
    "\n",
    "# Contador para el número de fotos guardadas\n",
    "photo_counter = 0\n",
    "\n",
    "while True:\n",
    "    # Leer un cuadro (frame) de la webcam\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"No se pudo obtener el cuadro de video\")\n",
    "        break\n",
    "    \n",
    "    # Obtener el alto y ancho del cuadro\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    # Calcular el tamaño del rectángulo para que ocupe el 80% del cuadro\n",
    "    rect_width = int(width * 0.95)\n",
    "    rect_height = int(height * 0.55)\n",
    "    \n",
    "    # Calcular el punto de inicio (superior izquierda) y final (inferior derecha) del rectángulo\n",
    "    start_point = (int((width - rect_width) / 2), int((height - rect_height) / 2))\n",
    "    end_point = (int((width + rect_width) / 2), int((height + rect_height) / 2))\n",
    "    \n",
    "    # Configurar el color y grosor del rectángulo\n",
    "    color = (0, 255, 0)  # Verde\n",
    "    thickness = 2        # Grosor de la línea\n",
    "    \n",
    "    # Dibujar el rectángulo en el cuadro\n",
    "    cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "    \n",
    "    # Mostrar el cuadro en una ventana\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # Leer la tecla presionada\n",
    "    key = cv2.waitKey(wait_time) & 0xFF\n",
    "    \n",
    "    # Si se presiona la tecla 'q', salir del bucle\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Si se presiona la tecla 'x', guardar la imagen dentro del recuadro\n",
    "    if key == ord('x'):\n",
    "        # Recortar la región del cuadro dentro del rectángulo\n",
    "        cropped_frame = frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "        \n",
    "        # Guardar la imagen recortada como un archivo\n",
    "        photo_filename = f'photo_card_{photo_counter}.png'\n",
    "        cv2.imwrite(photo_video_path +'/'+ photo_filename, cropped_frame)\n",
    "        print(f'Foto guardada: {photo_filename}')\n",
    "        plt.imshow(cropped_frame)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        photo_counter += 1\n",
    "\n",
    "# Liberar la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">**4. Predecir regiones de interes de la tarjeta de recarga (Deteccion).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO # type: ignore\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el modelo YOLOv8 (puedes usar 'best.pt' o 'last.pt')\n",
    "path_model = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\notebooks\\runs\\detect\\train\\weights\\best.pt'\n",
    "model = YOLO(path_model)\n",
    "\n",
    "# Generar un color aleatorio para cada clase\n",
    "def random_color():\n",
    "    return [random.randint(0, 255) for _ in range(3)]\n",
    "\n",
    "# Función para dibujar cajas\n",
    "def draw_boxes(img, boxes):\n",
    "    for box in boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        \n",
    "        # Obtener el color aleatorio para la clase\n",
    "        color = random_color()\n",
    "        \n",
    "        # Dibujar el rectángulo\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Agregar el texto de la clase y la confianza\n",
    "        class_id = int(cls)\n",
    "        label = f'{model.names[class_id]}: {conf:.2f}'\n",
    "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_PLAIN, 1.3, (57, 255, 20), 2)\n",
    "\n",
    "# Función para realizar la predicción\n",
    "def predict(image_path, output_image_path):\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Realizar la predicción\n",
    "    results = model(img)\n",
    "\n",
    "    # Iterar sobre los resultados\n",
    "    for result in results:  # Cada 'result' es un conjunto de detecciones para una imagen\n",
    "        draw_boxes(img, result.boxes)  # Dibuja las cajas en la imagen\n",
    "\n",
    "    # Guardar la imagen con las predicciones en el directorio especificado\n",
    "    cv2.imwrite(output_image_path, img)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "output_dir_predictions_simple = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\predictions_simple'\n",
    "os.makedirs(output_dir_predictions_simple, exist_ok=True)\n",
    "\n",
    "# Probar el modelo con una imagen\n",
    "photo_video_path= r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\data\\test_photos_video'\n",
    "\n",
    "images_cards=os.listdir(photo_video_path)\n",
    "\n",
    "for image_card in images_cards:\n",
    "    image_path=os.path.join(photo_video_path, image_card)    \n",
    "\n",
    "    output_image_path = os.path.join(output_dir_predictions_simple, f'prediction_{image_card}')  # Ruta de salida deseada\n",
    "    predict(image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">**5. Preprocesar imagenes de regiones de interes de la tarjeta de recarga.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recortar las regiones detectadas \n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO # type: ignore\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el modelo YOLOv8 (puedes usar 'best.pt' o 'last.pt')\n",
    "path_model = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\notebooks\\runs\\detect\\train\\weights\\best.pt'\n",
    "model = YOLO(path_model)\n",
    "\n",
    "# Generar un color aleatorio para cada clase\n",
    "def random_color():\n",
    "    return [random.randint(0, 255) for _ in range(3)]\n",
    "\n",
    "# Función para dibujar cajas y extraer imágenes de cada clase detectada\n",
    "def draw_boxes_and_save(img, boxes, output_dir, image_name):\n",
    "    for i, box in enumerate(boxes.data):\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        \n",
    "        # Obtener el color aleatorio para la clase\n",
    "        # color = random_color()\n",
    "        \n",
    "        # Dibujar el rectángulo\n",
    "        # cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Agregar el texto de la clase y la confianza\n",
    "        class_id = int(cls)\n",
    "        # label = f'{model.names[class_id]}: {conf:.2f}'\n",
    "        # cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_PLAIN, 1.3, (57, 255, 20), 2)\n",
    "\n",
    "        # Recortar y guardar la imagen de la clase detectada\n",
    "        cropped_img = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Crear el directorio para la clase si no existe\n",
    "        class_dir = os.path.join(output_dir, model.names[class_id])\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        # Guardar la imagen recortada con el nombre original + índice\n",
    "        cropped_image_path = os.path.join(class_dir, f'{image_name}_class_{model.names[class_id]}_{i}.jpg')\n",
    "        cv2.imwrite(cropped_image_path, cropped_img)\n",
    "        plt.imshow(cropped_img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "# Función para realizar la predicción y guardar imágenes por clase\n",
    "def predict(image_path, output_image_path):\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Obtener el nombre de la imagen (sin la extensión) para usarlo al guardar las subimágenes\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Realizar la predicción\n",
    "    results = model(img)\n",
    "\n",
    "    # Iterar sobre los resultados\n",
    "    for result in results:\n",
    "        draw_boxes_and_save(img, result.boxes, output_image_path, image_name)  # Dibuja cajas y guarda las imágenes por clase\n",
    "\n",
    "    # Guardar la imagen con las predicciones en el directorio especificado\n",
    "    cv2.imwrite(output_image_path, img)\n",
    "\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "output_dir_predictions_cropped_regions = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\predictions_cropped_regions'\n",
    "os.makedirs(output_dir_predictions_cropped_regions, exist_ok=True)\n",
    "\n",
    "# Probar el modelo con una imagen\n",
    "photo_video_path= r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\data\\test_photos_video'\n",
    "\n",
    "images_cards=os.listdir(photo_video_path)\n",
    "\n",
    "for image_card in images_cards:\n",
    "    image_path=os.path.join(photo_video_path, image_card)    \n",
    "    print(image_path)\n",
    "\n",
    "    output_image_path = os.path.join(output_dir_predictions_cropped_regions, f'prediction_{image_card}')  # Ruta de salida deseada\n",
    "    predict(image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocesar la imagen del PIN\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Cargar la imagen\n",
    "image_path = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\predictions_cropped_regions\\prediction_photo_card_0.png\\recharge_pin\\photo_card_0_class_recharge_pin_2.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Convertir la imagen a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicar desenfoque gaussiano para reducir el ruido\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Aplicar una binarización (umbral adaptativo) para mejorar el contraste del texto\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Mostrar la imagen preprocesada (opcional)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Guardar la imagen preprocesada\n",
    "output_dir_preprocessed_regions = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\preprocessed_regions'\n",
    "# output_preprocessed_image_path = os.path.join(output_dir_preprocessed_regions, f'preprocessed_{img}')  # Ruta de salida deseada\n",
    "image_name=os.path.basename(image_path)\n",
    "output_preprocessed_image_path = os.path.join(output_dir_preprocessed_regions, f'preprocessed_{image_name}')  # Ruta de salida deseada\n",
    "\n",
    "cv2.imwrite(output_preprocessed_image_path, thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=\"orange\">6. Reconocer caracteres con OCR de las regiones de interes detectadas.</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Version Tesseract\n",
    "# No funciona para todos los casos\n",
    "import pytesseract # type: ignore\n",
    "import cv2\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Leer la imagen\n",
    "# Imagen preprocesado\n",
    "image_path = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\preprocessed_regions\\preprocessed_photo_card_0_class_recharge_pin_2.jpg'\n",
    "\n",
    "# Imagen original\n",
    "# image_path = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\predictions_cropped_regions\\prediction_photo_card_0.png\\recharge_pin\\photo_card_0_class_recharge_pin_2.jpg'\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Usar Tesseract para hacer OCR en la imagen\n",
    "# custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789'\n",
    "# result = pytesseract.image_to_string(img, config=custom_config)\n",
    "\n",
    "result = pytesseract.image_to_string(img)\n",
    "\n",
    "# Mostrar el resultado original\n",
    "print(\"Resultado original del OCR:\", result)\n",
    "\n",
    "# Filtrar solo los números utilizando una expresión regular\n",
    "# numbers = re.findall(r'\\d+', result)\n",
    "\n",
    "# Unir los números en una cadena, si es necesario\n",
    "# filtered_numbers = ' '.join(numbers)\n",
    "\n",
    "# Mostrar el resultado filtrado\n",
    "# print(\"Números extraídos:\", filtered_numbers)\n",
    "\n",
    "# Unir los números en una cadena, si es necesario\n",
    "# filtered_numbers = ''.join(numbers)\n",
    "\n",
    "# Mostrar el resultado filtrado\n",
    "# print(\"Números extraídos sin espacios:\", filtered_numbers)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Version CnOcr\n",
    "from cnocr import CnOcr # type: ignore\n",
    "import cv2\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# En caso de advertencia generada en matplotlib, habilitar la siguiente linea\n",
    "# matplotlib.use('TkAgg')  # Cambia el backend a uno interactivo\n",
    "# %matplotlib inline\n",
    "\n",
    "# Inicializar el modelo CnOCR\n",
    "ocr = CnOcr()\n",
    "\n",
    "# Imagen preprocesado\n",
    "# image_path = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\preprocessed_regions\\preprocessed_photo_card_0_class_recharge_pin_2.jpg'\n",
    "\n",
    "# Imagen original\n",
    "image_path = r'C:\\Users\\VIC\\Downloads\\DELVE DEEP LEARNING\\PROYECTO_TARJETAS\\CODIGO_FUENTE_TARJETAS\\DataScience\\proyecto_jupyter\\models\\predictions_cropped_regions\\prediction_photo_card_0.png\\recharge_pin\\photo_card_0_class_recharge_pin_2.jpg'\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Realizar OCR utilizando CnOCR\n",
    "result = ocr.ocr_for_single_line(img)\n",
    "result = result.get('text','')\n",
    "\n",
    "\n",
    "# Mostrar el resultado original\n",
    "print(\"Resultado del OCR --->\", result)\n",
    "\n",
    "# Filtrar solo los números utilizando una expresión regular\n",
    "# numbers = re.findall(r'\\d+', result)\n",
    "\n",
    "# Unir los números en una cadena, si es necesario\n",
    "# filtered_numbers = ' '.join(numbers)\n",
    "\n",
    "# Mostrar el resultado filtrado\n",
    "# print(\"Números extraídos:\", filtered_numbers)\n",
    "\n",
    "# Unir los números en una cadena, si es necesario\n",
    "# filtered_numbers = ''.join(numbers)\n",
    "\n",
    "# Mostrar el resultado filtrado\n",
    "# print(\"Números extraídos sin espacios:\", filtered_numbers)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">**7. Marcar al numero de recarga de credito de la operadora de telefonos.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Operadora Detectada: Entel')\n",
    "print('Codigo de recarga: *109*17925642826252#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">**8. Guardar datos de la tarjeta de recarda detectada.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Los datos se almacenaron correctamente.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
